Adding New Cloud Providers
==========================

This document outlines the steps required to add support for a new cloud provider to the Borgitory cloud sync system.

Overview
--------

The cloud sync system is designed with a modular architecture that makes adding new providers straightforward. Each provider consists of:

- **Storage Configuration Schema**: Defines and validates provider-specific settings
- **Storage Implementation**: Handles the actual upload/download operations  
- **Frontend Templates**: Provides the user interface for configuration
- **Integration Points**: Connects the provider to the main system

Borgitory uses `rclone <https://rclone.org/>`_ for syncing. Borgitory can theoretically support any destination that rclone does.

Registry Pattern
---------------

Borgitory uses a **registry pattern** for cloud providers, which means:

- **No hardcoded provider lists**: Providers are automatically discovered
- **Dynamic registration**: Use the ``@register_provider`` decorator to register your provider
- **Automatic integration**: Once registered, your provider appears in APIs, validation, and frontend dropdowns
- **Metadata support**: Include provider capabilities like versioning support, encryption, etc.

This eliminates the need to manually update multiple files when adding a provider!

Step-by-Step Implementation Guide
--------------------------------

Step 1: Create the Storage Configuration Schema
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Create a new file: ``src/services/cloud_providers/storage/{provider_name}_storage.py``

.. code-block:: python

   """
   {Provider Name} cloud storage implementation.
   """

   from typing import Callable, Optional
   from pydantic import Field, field_validator, model_validator

   from .base import CloudStorage, CloudStorageConfig
   from ..types import SyncEvent, SyncEventType, ConnectionInfo
   from ..registry import register_provider
   from ...rclone_service import RcloneService


   class {ProviderName}StorageConfig(CloudStorageConfig):
       """Configuration for {Provider Name} storage"""

       # Define your provider-specific fields here
       # Example fields (customize based on your provider):
       endpoint_url: str = Field(..., min_length=1, description="Provider endpoint URL")
       api_key: str = Field(..., min_length=1, description="API key for authentication")
       bucket_name: str = Field(..., min_length=1, max_length=255, description="Bucket/container name")
       region: Optional[str] = Field(default=None, description="Region (if applicable)")

       @field_validator("endpoint_url")
       @classmethod
       def validate_endpoint_url(cls, v: str) -> str:
           """Validate endpoint URL format"""
           if not v.startswith(("http://", "https://")):
               raise ValueError("Endpoint URL must start with http:// or https://")
           return v

       @field_validator("api_key")
       @classmethod
       def validate_api_key(cls, v: str) -> str:
           """Validate API key format"""
           # Add your specific validation logic here
           if len(v) < 10:  # Example validation
               raise ValueError("API key must be at least 10 characters long")
           return v

       @field_validator("bucket_name")
       @classmethod
       def validate_bucket_name(cls, v: str) -> str:
           """Validate bucket name format"""
           # Add provider-specific bucket naming rules
           import re
           if not re.match(r'^[a-zA-Z0-9\-_]+$', v):
               raise ValueError("Bucket name can only contain letters, numbers, hyphens, and underscores")
           return v.lower()

       # Add model validator for complex validation if needed
       @model_validator(mode="after")
       def validate_config_combination(self):
           """Validate field combinations if needed"""
           # Example: certain fields might be mutually exclusive
           # or required together
           return self


   class {ProviderName}Storage(CloudStorage):
       """
       {Provider Name} cloud storage implementation.
       """

       def __init__(self, config: {ProviderName}StorageConfig, rclone_service: RcloneService):
           """
           Initialize {Provider Name} storage.

           Args:
               config: Validated {Provider Name} configuration
               rclone_service: Injected rclone service for I/O operations
           """
           self._config = config
           self._rclone_service = rclone_service

       async def upload_repository(
           self,
           repository_path: str,
           remote_path: str,
           progress_callback: Optional[Callable[[SyncEvent], None]] = None,
       ) -> None:
           """Upload repository to {Provider Name}"""
           if progress_callback:
               progress_callback(
                   SyncEvent(
                       type=SyncEventType.STARTED,
                       message=f"Starting {Provider Name} upload to {self._config.bucket_name}",
                   )
               )

           try:
               # Implement your upload logic here using rclone_service
               # Example structure:
               await self._rclone_service.upload_to_{provider_name}(
                   source_path=repository_path,
                   remote_path=remote_path,
                   endpoint_url=self._config.endpoint_url,
                   api_key=self._config.api_key,
                   bucket_name=self._config.bucket_name,
                   region=self._config.region,
                   progress_callback=progress_callback,
               )

               if progress_callback:
                   progress_callback(
                       SyncEvent(
                           type=SyncEventType.COMPLETED,
                           message=f"Successfully uploaded to {Provider Name}",
                       )
                   )

           except Exception as e:
               error_msg = f"Failed to upload to {Provider Name}: {str(e)}"
               if progress_callback:
                   progress_callback(
                       SyncEvent(
                           type=SyncEventType.ERROR,
                           message=error_msg,
                       )
                   )
               raise Exception(error_msg) from e

       async def test_connection(self) -> bool:
           """Test {Provider Name} connection"""
           try:
               result = await self._rclone_service.test_{provider_name}_connection(
                   endpoint_url=self._config.endpoint_url,
                   api_key=self._config.api_key,
                   bucket_name=self._config.bucket_name,
                   region=self._config.region,
               )
               return result.get("status") == "success"
           except Exception:
               return False

       def get_connection_info(self) -> ConnectionInfo:
           """Get {Provider Name} connection info for display"""
           return ConnectionInfo(
               provider="{provider_name}",
               details={
                   "endpoint": self._config.endpoint_url,
                   "bucket": self._config.bucket_name,
                   "region": self._config.region or "default",
                   "api_key": f"{self._config.api_key[:4]}***{self._config.api_key[-4:]}"
                   if len(self._config.api_key) > 8
                   else "***",
               },
           )

       def get_sensitive_fields(self) -> list[str]:
           """{Provider Name} sensitive fields that should be encrypted"""
           return ["api_key"]  # Add all sensitive field names here

       def get_display_details(self, config_dict: dict) -> dict:
           """Get {Provider Name}-specific display details for the UI"""
           endpoint = config_dict.get("endpoint_url", "Unknown")
           bucket = config_dict.get("bucket_name", "Unknown")
           region = config_dict.get("region", "default")
           
           provider_details = f"""
               <div><strong>Endpoint:</strong> {endpoint}</div>
               <div><strong>Bucket:</strong> {bucket}</div>
               <div><strong>Region:</strong> {region}</div>
           """.strip()
           
           return {
               "provider_name": "{Provider Display Name}",
               "provider_details": provider_details
           }


   @register_provider(
       name="{provider_name}",
       label="{Provider Display Name}",
       description="{Provider description}",
       supports_encryption=True,
       supports_versioning=False,  # Set to True if your provider supports versioning
       requires_credentials=True
   )
   class {ProviderName}Provider:
       """{Provider Name} provider registration"""
       config_class = {ProviderName}StorageConfig
       storage_class = {ProviderName}Storage

Step 2: Update the Storage Module Exports
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Edit ``src/services/cloud_providers/storage/__init__.py``:

.. code-block:: python

   from .{provider_name}_storage import {ProviderName}Storage, {ProviderName}StorageConfig

   __all__ = [
       # ... existing exports ...
       "{ProviderName}Storage",
       "{ProviderName}StorageConfig",
   ]

Step 3: Create Frontend Template
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Create ``src/borgitory/templates/partials/cloud_sync/providers/{provider_name}_fields.html``:

.. code-block:: html

   <!-- {Provider Name} Fields -->
   <div id="{provider_name}-fields">
       <div>
           <label class="block text-sm font-medium text-gray-900 dark:text-gray-100">Endpoint URL</label>
           <input type="text" name="provider_config[endpoint_url]" placeholder="https://api.{provider}.com" class="input-modern mt-1">
       </div>
       <div>
           <label class="block text-sm font-medium text-gray-900 dark:text-gray-100">API Key</label>
           <input type="password" name="provider_config[api_key]" class="input-modern mt-1">
       </div>
       <div>
           <label class="block text-sm font-medium text-gray-900 dark:text-gray-100">Bucket Name</label>
           <input type="text" name="provider_config[bucket_name]" placeholder="my-backup-bucket" class="input-modern mt-1">
       </div>
       <div>
           <label class="block text-sm font-medium text-gray-900 dark:text-gray-100">Region (optional)</label>
           <input type="text" name="provider_config[region]" placeholder="us-east-1" class="input-modern mt-1">
       </div>
       <div>
           <label class="block text-sm font-medium text-gray-900 dark:text-gray-100">Path Prefix (optional)</label>
           <input type="text" name="path_prefix" placeholder="backups/borgitory" class="input-modern mt-1">
       </div>
   </div>

Step 4: Template Integration (Automatic)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Good news!** With the current implementation, templates are automatically discovered by checking if the template file exists on the filesystem. You don't need to manually update any API context variables.

The system will automatically:

- Check if ``src/borgitory/templates/partials/cloud_sync/providers/{provider_name}_fields.html`` exists
- Include it in the provider fields if found
- Generate submit button text from registry metadata
- Handle provider validation through the registry

Simply create your template file and it will be automatically integrated!

What's Simplified by the Registry Pattern ‚ú®
-------------------------------------------

Thanks to the registry pattern, many things are automated:

- ‚úÖ **Provider Discovery**: Automatic detection via ``@register_provider`` decorator
- ‚úÖ **API Integration**: Providers appear in ``/api/cloud-sync/providers`` automatically
- ‚úÖ **Template Discovery**: Automatic filesystem-based template detection
- ‚úÖ **Submit Button Text**: Generated from registry metadata
- ‚úÖ **Configuration Validation**: Uses registered config classes
- ‚úÖ **Sensitive Field Detection**: Uses storage class methods

**Note**: Some manual steps are still required when adding new providers:

- Create template files manually
- Add rclone service methods for new providers
- Update this documentation with provider-specific details

Step 5: Implement Rclone Integration
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Add methods to ``src/services/rclone_service.py``:

.. code-block:: python

   async def sync_repository_to_{provider_name}(
       self,
       repository: Repository,
       endpoint_url: str,
       api_key: str,
       bucket_name: str,
       path_prefix: str = "",
       region: Optional[str] = None,
   ) -> AsyncGenerator[Dict, None]:
       """Sync repository to {Provider Name} using rclone"""
       try:
           # Build provider-specific rclone command
           # Example structure (adapt for your provider):
           command = [
               "rclone", "sync",
               repository.path,
               f":your-provider:{bucket_name}/{path_prefix}",
               "--progress", "--stats", "1s", "--verbose"
           ]
           
           # Add provider-specific flags
           command.extend([
               "--your-provider-endpoint", endpoint_url,
               "--your-provider-api-key", api_key,
           ])
           
           # Execute and yield progress (see existing methods for full implementation)
           process = await asyncio.create_subprocess_exec(
               *command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
           )
           
           # ... rest of implementation similar to existing methods
           
       except Exception as e:
           yield {"type": "error", "message": str(e)}

   async def test_{provider_name}_connection(
       self,
       endpoint_url: str,
       api_key: str,
       bucket_name: str,
       region: Optional[str] = None,
   ) -> Dict:
       """Test {Provider Name} connection"""
       try:
           # Test connection using rclone lsd or similar command
           command = [
               "rclone", "lsd", f":your-provider:{bucket_name}",
               "--your-provider-endpoint", endpoint_url,
               "--your-provider-api-key", api_key,
           ]
           
           process = await asyncio.create_subprocess_exec(
               *command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
           )
           
           stdout, stderr = await process.communicate()
           
           if process.returncode == 0:
               return {"status": "success"}
           else:
               return {"status": "error", "message": stderr.decode()}
               
       except Exception as e:
           return {"status": "error", "message": str(e)}

**Important**: After adding these methods, update the generic dispatcher methods in the same file:

.. code-block:: python

   # Add your provider to the generic sync_repository_to_provider method
   if provider == "{provider_name}":
       async for result in self.sync_repository_to_{provider_name}(
           repository=repository,
           endpoint_url=provider_config["endpoint_url"],
           api_key=provider_config["api_key"],
           bucket_name=provider_config["bucket_name"],
           path_prefix=provider_config.get("path_prefix", ""),
           region=provider_config.get("region"),
       ):
           yield result

   # Add your provider to the generic test_provider_connection method
   elif provider == "{provider_name}":
       return await self.test_{provider_name}_connection(
           endpoint_url=provider_config["endpoint_url"],
           api_key=provider_config["api_key"],
           bucket_name=provider_config["bucket_name"],
           region=provider_config.get("region"),
       )

Step 6: Create Tests
~~~~~~~~~~~~~~~~~~

Create ``tests/cloud_providers/test_{provider_name}_storage.py``:

.. code-block:: python

   import pytest
   from unittest.mock import Mock, AsyncMock
   from borgitory.services.cloud_providers.storage.{provider_name}_storage import (
       {ProviderName}StorageConfig,
       {ProviderName}Storage,
   )


   class Test{ProviderName}StorageConfig:
       """Test {Provider Name} storage configuration validation"""

       def test_valid_config(self):
           """Test valid configuration passes validation"""
           config = {ProviderName}StorageConfig(
               endpoint_url="https://api.{provider}.com",
               api_key="valid-api-key-12345",
               bucket_name="test-bucket",
               region="us-east-1",
           )
           assert config.endpoint_url == "https://api.{provider}.com"
           assert config.bucket_name == "test-bucket"

       def test_invalid_endpoint_url(self):
           """Test invalid endpoint URL raises validation error"""
           with pytest.raises(ValueError, match="Endpoint URL must start with"):
               {ProviderName}StorageConfig(
                   endpoint_url="invalid-url",
                   api_key="valid-api-key-12345",
                   bucket_name="test-bucket",
               )

       def test_invalid_api_key(self):
           """Test invalid API key raises validation error"""
           with pytest.raises(ValueError, match="API key must be at least"):
               {ProviderName}StorageConfig(
                   endpoint_url="https://api.{provider}.com",
                   api_key="short",
                   bucket_name="test-bucket",
               )


   class Test{ProviderName}Storage:
       """Test {Provider Name} storage implementation"""

       @pytest.fixture
       def mock_rclone_service(self):
           return AsyncMock()

       @pytest.fixture
       def storage_config(self):
           return {ProviderName}StorageConfig(
               endpoint_url="https://api.{provider}.com",
               api_key="valid-api-key-12345",
               bucket_name="test-bucket",
               region="us-east-1",
           )

       @pytest.fixture
       def storage(self, storage_config, mock_rclone_service):
           return {ProviderName}Storage(storage_config, mock_rclone_service)

       @pytest.mark.asyncio
       async def test_test_connection_success(self, storage, mock_rclone_service):
           """Test successful connection test"""
           mock_rclone_service.test_{provider_name}_connection.return_value = {
               "status": "success"
           }
           
           result = await storage.test_connection()
           assert result is True

       @pytest.mark.asyncio
       async def test_test_connection_failure(self, storage, mock_rclone_service):
           """Test failed connection test"""
           mock_rclone_service.test_{provider_name}_connection.side_effect = Exception("Connection failed")
           
           result = await storage.test_connection()
           assert result is False

       def test_get_sensitive_fields(self, storage):
           """Test sensitive fields are correctly identified"""
           sensitive_fields = storage.get_sensitive_fields()
           assert "api_key" in sensitive_fields

       def test_get_connection_info(self, storage):
           """Test connection info formatting"""
           info = storage.get_connection_info()
           assert info.provider == "{provider_name}"
           assert "api_key" in info.details
           assert "***" in info.details["api_key"]  # Should be masked

Testing Your Implementation
--------------------------

Configuration Validation Tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: bash

   python -c "
   import sys; sys.path.append('src')
   from borgitory.services.cloud_providers.storage.{provider_name}_storage import {ProviderName}StorageConfig
   config = {ProviderName}StorageConfig(
       endpoint_url='https://api.{provider}.com',
       api_key='valid-api-key-12345',
       bucket_name='test-bucket'
   )
   print('Configuration validation passed!')
   "

Unit Tests
~~~~~~~~~

.. code-block:: bash

   python -m pytest tests/cloud_providers/test_{provider_name}_storage.py -v

Integration Tests
~~~~~~~~~~~~~~~

.. code-block:: bash

   python -m pytest tests/cloud_sync/ -v

Full Cloud Provider Test Suite
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: bash

   python -m pytest tests/cloud_providers/ -v

Registry Integration Test
~~~~~~~~~~~~~~~~~~~~~~~

Verify your provider is automatically registered:

.. code-block:: bash

   python -c "
   import sys; sys.path.append('src')
   from borgitory.services.cloud_providers.registry import get_supported_providers, get_all_provider_info

   # Import your storage module to trigger registration
   from borgitory.services.cloud_providers.storage.{provider_name}_storage import {ProviderName}Provider

   print('Registered providers:', get_supported_providers())
   info = get_all_provider_info()
   if '{provider_name}' in info:
       print('‚úÖ {Provider Name} successfully registered!')
       print('Metadata:', info['{provider_name}'])
   else:
       print('‚ùå {Provider Name} not found in registry')
   "

Frontend Testing
~~~~~~~~~~~~~~

- Start the application
- Navigate to Cloud Sync settings
- Your provider should automatically appear in the dropdown (thanks to the registry!)
- Select your provider and verify the form fields appear correctly
- Try creating a configuration (will fail without real credentials, but should show proper validation)

Common Pitfalls
---------------

1. **Sensitive Fields**: Make sure to add all sensitive fields to ``get_sensitive_fields()`` and update the service layer detection
2. **Form Field Names**: Use bracket notation in templates: ``provider_config[field_name]``
3. **Validation**: Add comprehensive validation in the config class - this is your first line of defense
4. **Error Handling**: Provide clear error messages in validation and connection testing
5. **Rclone Integration**: The rclone service methods need to match your provider's rclone backend capabilities
6. **Testing**: Create both unit tests for the storage classes and integration tests for the full flow

Provider-Specific Considerations
-------------------------------

For Object Storage Providers (S3-like)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- Follow S3 patterns for bucket naming, regions, storage classes
- Consider implementing storage class options if supported
- Add endpoint URL validation for custom S3-compatible services

For File Transfer Providers (SFTP-like)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- Focus on connection authentication (keys, passwords, certificates)
- Validate host/port combinations
- Consider connection timeout and retry logic

For API-based Providers
~~~~~~~~~~~~~~~~~~~~~

- Implement proper API key validation and formatting
- Add rate limiting considerations
- Handle API versioning if applicable

Enhanced Rclone Integration Pattern
----------------------------------

The system includes an enhanced rclone integration pattern that automates parameter mapping and provides generic dispatcher methods.

RcloneMethodMapping
~~~~~~~~~~~~~~~~~

Each provider can define how its configuration maps to rclone method parameters:

.. code-block:: python

   from borgitory.services.cloud_providers.registry import RcloneMethodMapping

   mapping = RcloneMethodMapping(
       sync_method="sync_repository_to_s3",           # RcloneService method name
       test_method="test_s3_connection",              # Connection test method name
       parameter_mapping={
           "access_key": "access_key_id",             # config_field -> rclone_param
           "secret_key": "secret_access_key",
           "bucket_name": "bucket_name",
           "region": "region"
       },
       required_params=["repository", "access_key_id", "secret_access_key", "bucket_name"],
       optional_params={"region": "us-east-1", "path_prefix": ""}
   )

Two Ways to Define Rclone Mapping
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Option 1: In Registration Decorator**

.. code-block:: python

   @register_provider(
       name="myprovider",
       label="My Provider",
       rclone_mapping=mapping
   )
   class MyProvider:
       config_class = MyProviderConfig
       storage_class = MyProviderStorage

**Option 2: Auto-Discovery from Storage Class**

.. code-block:: python

   class MyProviderStorage(CloudStorage):
       @classmethod
       def get_rclone_mapping(cls) -> RcloneMethodMapping:
           return RcloneMethodMapping(
               sync_method="sync_repository_to_myprovider",
               test_method="test_myprovider_connection",
               parameter_mapping={"field": "param"},
               required_params=["repository", "param"]
           )

   @register_provider(name="myprovider", label="My Provider")  # No explicit mapping needed
   class MyProvider:
       config_class = MyProviderConfig
       storage_class = MyProviderStorage

Final Steps
----------

1. **That's it!** üéâ With the registry pattern, your provider is automatically:
   
   - Available in API endpoints (``/api/cloud-sync/providers``)
   - Included in validation and error messages
   - Visible in frontend dropdowns
   - Integrated with the service layer

2. Update this documentation with any provider-specific details
3. Add the provider to the main README.md supported providers list
4. Consider adding provider-specific documentation in the ``docs/`` folder
5. Update any deployment documentation if new dependencies are required

Registry Pattern Benefits
------------------------

The registry pattern provides these key advantages:

**‚úÖ Automatic Integration**

- Your provider appears in API endpoints (``/api/cloud-sync/providers``) automatically
- Frontend dropdowns populate without manual updates
- Validation includes your provider without code changes

**‚úÖ Zero Boilerplate**

- No hardcoded if/elif chains in service classes
- No manual provider lists to maintain
- No enum updates required

**‚úÖ Dynamic Capabilities**

- Provider metadata (encryption support, versioning, etc.) drives UI behavior
- Error messages automatically include your provider in "supported providers" lists
- Submit button text generated from registry metadata

**‚úÖ Type Safety**

- Pydantic validators use registry for provider validation
- Comprehensive error messages with available providers
- Runtime provider discovery with compile-time safety

**‚úÖ Developer Experience**

- Add one decorator, get full integration
- Consistent patterns across all providers
- Self-documenting through metadata

**Before Registry Pattern:**

.. code-block:: text

   1. Create storage classes ‚úèÔ∏è
   2. Update provider enum ‚úèÔ∏è
   3. Update service layer ‚úèÔ∏è
   4. Update API endpoints ‚úèÔ∏è
   5. Update validation logic ‚úèÔ∏è
   6. Update frontend templates ‚úèÔ∏è
   7. Update sensitive field detection ‚úèÔ∏è

**With Registry Pattern:**

.. code-block:: text

   1. Create storage classes ‚úèÔ∏è
   2. Add @register_provider decorator ‚ú®
   3. Create frontend template ‚úèÔ∏è
   4. Add rclone service methods ‚úèÔ∏è
   5. Update rclone dispatcher methods ‚úèÔ∏è

Much simpler! üéâ

Current Limitations
------------------

While the registry pattern significantly simplifies adding new providers, some manual steps remain:

**Manual Steps Still Required**

- **Template Creation**: Template files must be created manually (though they're auto-discovered)
- **Rclone Methods**: Provider-specific rclone methods must be implemented in ``RcloneService``
- **Testing**: Comprehensive test suites should be written

**What's Now Automated**

- **Rclone Dispatchers**: Generic dispatcher methods automatically route to provider-specific methods using registry
- **Parameter Mapping**: Configuration parameters are automatically mapped to rclone method parameters
- **Validation**: Comprehensive validation of rclone integration is available

**Future Improvements**

- Auto-generate basic template files from provider metadata
- Create more generic rclone integration patterns
- Add provider validation CLI tool
- Implement template generation from borgitory.config schemas
